<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">


<!--
Font-awesome icons ie github or twitter
-->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/brands.css" integrity="sha384-n9+6/aSqa9lBidZMRCQHTHKJscPq6NW4pCQBiMmHdUCvPN8ZOg2zJJTkC7WIezWv" crossorigin="anonymous">

<!--
Google fonts api stuff
-->
<link href='https://fonts.googleapis.com/css?family=Verdana' rel='stylesheet'>



<title>Unsupervised Learning on the Health and Retirement Study using Geometric Data Analysis</title>

<script src="reitest_poster_v4_files/kePrint-0.0.1/kePrint.js"></script>




<style>
@page {
size: 36in 44in;
margin: 0;
padding: 0;
}
body {
margin: 0;
font-size: 35px;
width: 36in;
height: 44in;
padding: 0;
text-align: justify;
font-family: Verdana;
}
.poster_wrap {
width: 36in;
height: 44in;
padding: 0cm;
}
.title_container {
width: 36in;
height: calc(44in * 0.15);
overflow: hidden;
background-color: #532d8e;
border: 0 solid #B1B3B5;
}
.logo_left {
float: left;
width: 10%;
height: 100%;
background-color: #532d8e;
display: flex;
align-items: center;
justify-content: center;
}
.logo_right {
float: right;
width: 10%;
height: 100%;
background-color: #532d8e;
display: flex;
align-items: center;
justify-content: center;
}
.poster_title {
text-align: center;
position: relative;
float: left;
width: 80%;
height: 100%;
color: #FFFFFF;
top: 50%;
transform: translateY(-50%);
-webkit-transform: translateY(-50%);
}
#title {
font-family: Verdana;
}
/* unvisited link */
a:link {
color: #AF95D3;
}
.mybreak {
  break-before: column;
}
/* visited link */
a:visited {
color: #AF95D3;
}

/* mouse over link */
a:hover {
color: #AF95D3;
}

/* selected link */
a:active {
color: #AF95D3;
}
.poster_body {
-webkit-column-count: 3; /* Chrome, Safari, Opera */
-moz-column-count: 3; /* Firefox */
column-count: 3;
-webkit-column-fill: auto;
-moz-column-fill: auto;
column-fill: auto;
-webkit-column-rule-width: 1mm;
-moz-column-rule-width: 1mm;
column-rule-width: 1mm;
-webkit-column-rule-style: dashed;
-moz-column-rule-style: dashed;
column-rule-style: dashed;
-webkit-column-rule-color: #532d8e;
-moz-column-rule-color: #532d8e;
column-rule-color: #532d8e;
column-gap: 1em;
padding-left: 0.5em;
padding-right: 0.5em;
height: 100%;
color: #000000
background-color: #ffffff;
}
.poster_title h1 {
font-size: 65pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_body_wrap{
width: calc(36in + 0 + 0);
height: calc(44in * 0.83);
padding-top: calc(44in * 0.005);
padding-bottom: calc(44in * 0.01);
background-color: #ffffff;
}
.poster_title h3 {
color: #B1B3B5;
font-size: 50pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_title h3 > sup {
  font-size: 35pt;
  margin-left: 0.02em;
}
.poster_title h5 {
color: #FFFFFF;
font-size: 35pt;
margin: 0;
border: 0;
font-weight: normal;
}
img {
margin-top: 2cm;
margin-bottom: 0;
}
.section {
  padding: 0.2em;
}
.poster_body h1 {
text-align: center;
color: #FFFFFF;
font-size: 45pt;
border: 2mm solid #532d8e;
background-color: #532d8e;
border-radius: 4mm 0mm;
margin-top: 2mm;
margin-bottom: 2mm;
font-weight: normal;
}
.poster_body h2 {
color: #000000;
font-size: 40pt;
padding-left: 4mm;
font-weight: normal;
}
.span {
width: 200%;
}
/* center align leaflet map,
from https://stackoverflow.com/questions/52112119/center-leaflet-in-a-rmarkdown-document */
.html-widget {
margin: auto;
position: sticky;
margin-top: 2cm;
margin-bottom: 2cm;
}
.leaflet.html-widget.html-widget-static-bound.leaflet-container.leaflet-touch.leaflet-fade-anim.leaflet-grab.leaflet-touch-drag.leaflet-touch-zoom {
position: sticky;
width: 100%;
}
pre.sourceCode.r {
background-color: #dddddd40;
border-radius: 4mm;
padding: 4mm;
width: 75%;
/* align-items: center; */
margin: auto;
padding-left: 2cm;
}
code.sourceCode.r{
background-color: transparent;
font-size: 20pt;
border-radius: 2mm;
}
.caption {
font-size: 25pt;
}
.table caption {
font-size: 25pt;
padding-bottom: 3mm;

}
code {
font-size: 1em;
font-family: monospace;
background-color: #B1B3B524;
color: #532d8e;
padding: 1.2mm;
border-radius: 2mm;
}
.poster_title code {
font-size: 1em;
}
table {
font-size: 40px;
margin: auto;
border-top: 3px solid #666;
border-bottom: 3px solid #666;
}
table thead th {
border-bottom: 3px solid #ddd;
}
td {
padding: 8px;
}
th {
padding: 15px;
}
caption {
margin-bottom: 10px;
}
.poster_body p {
margin-right: 4mm;
margin-left: 4mm;
margin-top: 6mm;
margin-bottom: 10mm;
}
.poster_body ol {
margin-right: 4mm;
margin-left: 4mm;
}
#ul {
margin-right: 4mm;
margin-left: 4mm;
}
.references p {
font-size: 20pt;
}
.orcid img {
  width: 1em;
}
</style>
</head>
<body>


<div class="poster_wrap">
<div class="title_container">
<!-- Left Logo  -->
<div class="logo_left">
</div>
<!-- Poster Title -->
<div class= "poster_title">
<h1 id="title">Unsupervised Learning on the Health and Retirement Study using Geometric Data Analysis</h1>
<h3 id="author">Reinaldo Sanchez-Arias<sup>1</sup>, Roberto Williams Batista<sup>1</sup></h3><br>
<h5 id="affiliation"><sup>1</sup> Department of Data Science and Business Analytics, Florida Polytechnic University</h5>
</div>
<!-- Right Logo  -->
<div class="logo_right">
<img src=figs/FLPolyFullLogo_CMYK.jpg style="width: 80%">
</div>
</div>

<div class='poster_body_wrap'>
<div class='poster_body'>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The main focus of this work is to show the ability of geometric data analysis techniques in discovering response patterns in survey data where the majority of measurements result in categorical variables.</p>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<p>The geometric data analysis method of Multiple Correspondence Analysis (MCA) allows the construction of a lower dimensional space that captures the variance in the original data, and in which both variables and individuals can be projected to explore patterns, validate hypotheses, and better understand the association among the observed data. MCA is an unsupervised learning algorithm under the framework of Geometric Data Analysis (GDA), in which the elements of two sets indexing the entries of the data table become points in a geometric space and define two clouds of points: a <em>cloud of categories</em> and a <em>cloud of individuals</em> (Figure <a href="#fig:mcaIdea">1</a>). The distance between individual points is a reflection of the <em>dissimilarity between response patterns</em> of individuals, and both resulting clouds are on the same distance scale <span class="citation">(Le Roux and Rouanet 2010)</span>.</p>
<!-- MCA can be seen as a particular case of weighted principal component analysis, in which a set of multidimensional points exists in a high-dimensional space where distance is measured by a weighted Euclidean metric and the points themselves have differential masses. -->
<p>The lower dimensional representation is obtained by determining the closest plane to the points in terms of weighted least-squared distance, and then projecting the points onto the plane for visualization and interpretation. The solution can be obtained compactly and neatly using the generalized singular value decomposition (SVD) of the data matrix.</p>
<!-- \begin{figure}[!t]  -->
<!-- \centering  -->
<!-- \includegraphics[width=3.5in]{figs/mcaIdeaNew.pdf} -->
<!-- \caption{Clouds of points generated by MCA} -->
<!-- \label{fig:fig_MCAillustration}  -->
<!-- \end{figure} -->
<div class="figure" style="text-align: center"><span id="fig:mcaIdea"></span>
<img src="figs/MCAplot.png" alt="MCA idea" width="60%" />
<p class="caption">
Figure 1: MCA idea
</p>
</div>
<p>The squared distance between two respondents is calculated using the variables for which each had chosen different categories:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}[b]
\label{eq:distInd}
d^2(i, i^{\prime}) &amp;= \frac{1}{Q} \sum_{k\in K} \frac{(\delta_{ik} - \delta_{i^{\prime}k})^2}{f_k}  
\end{aligned}
\end{equation}\]</span>
where <span class="math inline">\(\delta_{ik} = 1\)</span> if <span class="math inline">\(i\)</span> has chosen <span class="math inline">\(k\)</span> and <span class="math inline">\(0\)</span> otherwise, and <span class="math inline">\(f_k\)</span> is the relative frequency of respondents who chose category <span class="math inline">\(k\)</span>. Notice that the smaller the frequencies of disagreement categories, the greater the distance between individuals. The set of all distances between individuals determines the cloud of individuals consisting of <span class="math inline">\(N\)</span> points in a space with dimensionality <span class="math inline">\(L\leq K - Q\)</span>  (it is assumed here that <span class="math inline">\(N &gt; L\)</span>). Additionally, if respondent <span class="math inline">\(i\)</span> chooses infrequent categories, then the point <span class="math inline">\(M^i\)</span> representing individual <span class="math inline">\(i\)</span> is far from the mean center of the cloud <span class="math inline">\(G\)</span>. The squared distance from point <span class="math inline">\(M^i\)</span> to <span class="math inline">\(G\)</span> is given by</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}[b]
\label{eq:distGM}
(GM^i)^2 &amp;= \left( \frac{1}{Q} \sum_{k\in K} \frac{\delta_{ik}}{f_k}  \right) -1
\end{aligned}
\end{equation}\]</span></p>
<p>In the cloud of categories, a weighted cloud of <span class="math inline">\(K\)</span> points, category <span class="math inline">\(k\)</span> is denoted by point <span class="math inline">\(M^k\)</span> with weight <span class="math inline">\(n_k\)</span>: For each question, the sum of the weights of category points is <span class="math inline">\(N\)</span>, and the relative weight <span class="math inline">\(p_k\)</span> of point <span class="math inline">\(M^k\)</span> is simply <span class="math inline">\(p_k = f_k=Q\)</span>.</p>
<!-- Given two categories $k$ and $k^\prime$, the squared distance between the points $M^k$ and $M^{k^\prime}$ is calculated as -->
<!-- \begin{equation} -->
<!-- \begin{aligned}[b] -->
<!-- \label{eq:distCat} -->
<!-- (M^k, M^{k^{\prime}})^2 &= \frac{n_k + n_{k^\prime} - 2 n_{kk^\prime} }{n_k n_{k^\prime}/N} -->
<!-- \end{aligned} -->
<!-- \end{equation} -->
<!-- with $n_{kk^\prime}$ denoting the number of respondents who have chosen both categories $k$ and $k^\prime.$ -->
<!-- The contribution of a category point $M^k$ to the overall variance is the ratio of the amount of the variance of the cloud due to category $k$. The contribution of a question $q$ is the sum of the contributions of its categories. Contributions can be calculated as shown below: -->
<!-- \begin{equation} -->
<!-- \begin{aligned}[b] -->
<!-- \label{eq:contribMk} -->
<!-- \text{Ctr}_k &= \frac{1-f_k}{K-Q}, \quad \text{Ctr}_q = \frac{K_q -1 }{K-Q} -->
<!-- \end{aligned} -->
<!-- \end{equation} -->
</div>
<div id="the-hrs-dataset" class="section level1">
<h1>The HRS Dataset</h1>
<p>Created in 1990 and launched in 1992 by the National Institute on Aging (NIA) and Social Security Administration, the Health and Retirement Study (HRS) surveys collect every two years of data from more than 22,000 Americans over 50 years old. It is the first longitudinal study of Americans approaching the economic and health aspects in the same survey and being the largest nationally representative multidisciplinary panel study of Americans aged 50 and older. The study was created and maintained by the Institute for Social Research (ISR) Survey Research Center (SRC) at the University of Michigan.</p>
<p>This study uses the following data products: HRS Core Cognition Section (D), HRS Left-Behind Questionnaires Section LB, and the RAND HRS Longitudinal File 2014 (V2). All the data used in this work was related to the survey waves of 2006, 2008, 2010 and 2012.</p>
</div>
<div id="results-and-discussion" class="section level1">
<h1>Results and Discussion</h1>
<p>MCA was performed on a combined dataset from respondents of the 2008 and 2010 waves. Notice that the participants of the 2008 survey are different than those from the 2010 survey. The clouds patterns for every wave were examined to confirm that the overall geometric representations were similar regardless of the number of participants in each wave, or the year in which the survey responses were collected.</p>
<table class="table table-striped" style="font-size: 25px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-3">Table 1: </span>Coordinates of the first 4 dimensions for the top 12 categories (sorted by contribution and level of agreement)
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
Dim 1
</th>
<th style="text-align:left;">
Dim 2
</th>
<th style="text-align:left;">
Dim 3
</th>
<th style="text-align:left;">
Dim 4
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
sophisticated Not at all
</td>
<td style="text-align:left;">
0.52
</td>
<td style="text-align:left;">
0.32
</td>
<td style="text-align:left;">
0.03
</td>
<td style="text-align:left;">
-0.14
</td>
</tr>
<tr>
<td style="text-align:left;">
imaginative A lot
</td>
<td style="text-align:left;">
-0.75
</td>
<td style="text-align:left;">
0.23
</td>
<td style="text-align:left;">
-0.20
</td>
<td style="text-align:left;">
0.04
</td>
</tr>
<tr>
<td style="text-align:left;">
creative A lot
</td>
<td style="text-align:left;">
-0.72
</td>
<td style="text-align:left;">
0.25
</td>
<td style="text-align:left;">
-0.23
</td>
<td style="text-align:left;">
0.03
</td>
</tr>
<tr>
<td style="text-align:left;">
caring A little
</td>
<td style="text-align:left;">
1.66
</td>
<td style="text-align:left;">
1.09
</td>
<td style="text-align:left;">
-1.90
</td>
<td style="text-align:left;">
0.58
</td>
</tr>
<tr>
<td style="text-align:left;">
talkactive A lot
</td>
<td style="text-align:left;">
-0.53
</td>
<td style="text-align:left;">
0.22
</td>
<td style="text-align:left;">
-0.03
</td>
<td style="text-align:left;">
-0.35
</td>
</tr>
<tr>
<td style="text-align:left;">
friendly A little
</td>
<td style="text-align:left;">
1.64
</td>
<td style="text-align:left;">
1.23
</td>
<td style="text-align:left;">
-1.73
</td>
<td style="text-align:left;">
0.19
</td>
</tr>
<tr>
<td style="text-align:left;">
careless Some
</td>
<td style="text-align:left;">
0.32
</td>
<td style="text-align:left;">
0.08
</td>
<td style="text-align:left;">
0.10
</td>
<td style="text-align:left;">
-0.68
</td>
</tr>
<tr>
<td style="text-align:left;">
responsible A little
</td>
<td style="text-align:left;">
1.71
</td>
<td style="text-align:left;">
1.31
</td>
<td style="text-align:left;">
-1.53
</td>
<td style="text-align:left;">
-0.18
</td>
</tr>
<tr>
<td style="text-align:left;">
responsible Some
</td>
<td style="text-align:left;">
0.94
</td>
<td style="text-align:left;">
-0.33
</td>
<td style="text-align:left;">
0.07
</td>
<td style="text-align:left;">
-0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
nervous Not at all
</td>
<td style="text-align:left;">
-0.31
</td>
<td style="text-align:left;">
0.22
</td>
<td style="text-align:left;">
-0.19
</td>
<td style="text-align:left;">
0.81
</td>
</tr>
<tr>
<td style="text-align:left;">
worry Not at all
</td>
<td style="text-align:left;">
-0.34
</td>
<td style="text-align:left;">
0.39
</td>
<td style="text-align:left;">
-0.27
</td>
<td style="text-align:left;">
1.11
</td>
</tr>
<tr>
<td style="text-align:left;">
moody Some
</td>
<td style="text-align:left;">
0.27
</td>
<td style="text-align:left;">
0.02
</td>
<td style="text-align:left;">
0.07
</td>
<td style="text-align:left;">
-0.70
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="font-size: 25px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-4">Table 2: </span>Variances of Axes, Varianceand Modified Rates
</caption>
<thead>
<tr>
<th style="text-align:left;">
Axes
</th>
<th style="text-align:right;">
1
</th>
<th style="text-align:right;">
2
</th>
<th style="text-align:right;">
3
</th>
<th style="text-align:right;">
4
</th>
<th style="text-align:right;">
5
</th>
<th style="text-align:right;">
6
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Eigenvalue <span class="math inline">\(( \lambda_l )\)</span>
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.142
</td>
<td style="text-align:right;">
0.086
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
0.070
</td>
<td style="text-align:right;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Modified variance rate <span class="math inline">\(( \tau_l )\)</span>
</td>
<td style="text-align:right;">
0.688
</td>
<td style="text-align:right;">
0.180
</td>
<td style="text-align:right;">
0.039
</td>
<td style="text-align:right;">
0.038
</td>
<td style="text-align:right;">
0.019
</td>
<td style="text-align:right;">
0.012
</td>
</tr>
</tbody>
</table>
<p>In this work, the R packages <code>dplyr</code> <span class="citation">(Wickham et al. 2018)</span> was used for data wrangling, and the <code>haven</code> package <span class="citation">(Wickham and Miller 2018)</span> for importing data. The MCA algorithm used in this study corresponds to the implementation of the algorithm available in the <code>FactoMineR</code> package <span class="citation">(Lê et al. 2008)</span>, that includes a collection of methods for multivariate data analysis.</p>
<!-- You can reference tables like so: Table \@ref(tab:mytable).  -->
<!-- \begin{table} -->
<!-- \caption{Response frequencies (absolute $n_k$ and relative $f_k$), and contributions ($\text{Ctr}_k$) of  top categories by $\text{Ctr}_k$ and levels} -->
<!-- \centering -->
<!-- \begin{tabular}{lrrr} -->
<!--   \hline -->
<!--   Category & nk & fk & ctrk \\  -->
<!--   \hline -->
<!--   sophisticated\_Not at all & 2159 & 0.22 & 0.0093 \\  -->
<!--   imaginative\_A lot & 3109 & 0.32 & 0.0081 \\  -->
<!--   creative\_A lot & 2668 & 0.27 & 0.0086 \\  -->
<!--   caring\_A little & 345 & 0.04 & 0.011 \\  -->
<!--   talkactive\_A lot & 2823 & 0.29 & 0.0085 \\  -->
<!--   friendly\_A little & 372 & 0.04 & 0.011 \\  -->
<!--   careless\_Some & 993 & 0.10 & 0.011 \\  -->
<!--   responsible\_Some & 1729 & 0.18 & 0.0098 \\  -->
<!--   responsible\_A little & 236 & 0.02 & 0.012 \\  -->
<!--   nervous\_Not at all & 3101 & 0.32 & 0.0081 \\  -->
<!--   worry\_Not at all & 1625 & 0.17 & 0.0099 \\  -->
<!--   moody\_Some & 1470 & 0.15 & 0.01 \\  -->
<!--    \hline -->
<!-- \end{tabular} -->
<!-- \label{tab:fknkTop12} -->
<!-- \end{table} -->
<!-- `NEED TO ADD TABLES TO POSTER` -->
<!-- \begin{figure}[h!]  -->
<!-- \centering  -->
<!-- \includegraphics[width=3in]{../figs/newbiplot12.pdf} -->
<!-- \caption{Projection onto the first two principal dimensions} -->
<!-- \label{fig:biplot}  -->
<!-- \end{figure}  -->
</div>
<div id="clustering" class="section level1">
<h1>Clustering</h1>
<p>Geometric data analysis methods have the potential to be used as a pre-processing step for clustering, given the representation in a lower dimensional space provided by the principal component technique of choice. In this work, a hierarchical clustering algorithm is performed using the coordinates of each respondent in the lower dimensional space generated by the MCA procedure.</p>
<p>The findings of this hierarchical clustering confirm a natural grouping for the participants of the survey: the tendency of survey respondent to use the levels of agreement with the different questions that are part of the questionnaire, namely, “a lot”, “not at all”, “some” and “a little”. These levels of agreements are well separated in distinct regions within the plane of the first 2 principal dimensions.</p>
<p>The four regions shown in (Figure <a href="#fig:regions12">3</a>), express consistency category levels of the variables related to the personality scale <span class="citation">(Lachman and Weaver 1997)</span> supplied by the HRS Core LB dataset.
The individuals present in Region 1 have an open personality and actively seek for new experiences, while individuals in Region 3 and 4 do not exhibit this characteristic, holding all the low levels of this perception which is defined by a “Not at all” response in most cases. Similarly, the aspect of conscientiousness is a substantial characteristic for individuals in Region 1, and its weakest trace is found in individuals located in Regions 3 and 4.</p>
<!-- \begin{figure}[h!]  -->
<!-- \centering  -->
<!-- \includegraphics[width=3.2in]{../figs/new_hclust.pdf} -->
<!-- \caption{Hierarchical clustering using principal dimensions generated by multiple correspondence analysis.} -->
<!-- \label{fig:hclust}  -->
<!-- \end{figure}  -->
<div class="figure" style="text-align: center"><span id="fig:hclust"></span>
<img src="figs/screeplot.png" alt="Hierarchical Clustering" width="50%" /><img src="figs/new_hclust.png" alt="Hierarchical Clustering" width="50%" />
<p class="caption">
Figure 2: Hierarchical Clustering
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:regions12"></span>
<img src="figs/region_1_plot.png" alt="Regions" width="50%" /><img src="figs/region_2_plot.png" alt="Regions" width="50%" /><img src="figs/region_3_plot.png" alt="Regions" width="50%" /><img src="figs/region_4_plot.png" alt="Regions" width="50%" />
<p class="caption">
Figure 3: Regions
</p>
</div>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>The use of unsupervised techniques presented in this work represents an opportunity to extract valuable insights from longitudinal datasets like the one made available by the US Health and Retirement Study. MCA allows for new interpretations and discovery of patterns that take advantage of the qualitative nature of the data collected from survey respondents. The hierarchical clustering technique applied to the low dimensional representation of participants, provided by the MCA method, suggested a reasonable separation of the respondent profile as characterized by a personality scale. Results provided by this approach may be used to explore other areas that have yet to be captured using the items in the questionnaires, helping in the design of the survey and sampling procedure, and allowing for correlation studies with other physical and mental health indicators.</p>
</div>
<div id="acknowledgements" class="section level1">
<h1>Acknowledgements</h1>
<p>The HRS (Health and Retirement Study) is sponsored by the National Institute on Aging (grant number NIA U01AG009740) and is conducted by the University of Michigan. The HRS has been approved by the Institutional Review Board at the University of Michigan. The HRS obtains informed verbal consent from voluntary participants and follows strict procedures to protect study participants from disclosure (including maintaining a Federal Certificate of Confidentiality). The public data, made available to registered researchers and used in this study, is de-identified.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-lachman1997midlife">
<p>Lachman, Margie E, and Suzanne L Weaver. 1997. “The Midlife Development Inventory (MIDI) Personality Scales: Scale Construction and Scoring.” <em>Waltham, MA: Brandeis University</em>, 1–9.</p>
</div>
<div id="ref-le2010multiple">
<p>Le Roux, Brigitte, and Henry Rouanet. 2010. <em>Multiple Correspondence Analysis</em>. Vol. 163. Sage.</p>
</div>
<div id="ref-le2008factominer">
<p>Lê, Sébastien, Julie Josse, François Husson, and others. 2008. “FactoMineR: An R Package for Multivariate Analysis.” <em>Journal of Statistical Software</em> 25 (1). Los Angeles: 1–18.</p>
</div>
<div id="ref-Refdplyr">
<p>Wickham, Hadley, Romain Francois, Lionel Henry, and Kirill Müller. 2018. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div id="ref-wickham2018haven">
<p>Wickham, Hadley, and Evan Miller. 2018. “Haven: Import and Export SPSS, STATA and SAS Files.” <em>R Package Version</em> 1 (0).</p>
</div>
</div>
</div>
</div>
</div>

</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
var script = document.createElement("script");
script.type = "text/javascript";
var src = "true";
if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
if (location.protocol !== "file:" && /^https?:/.test(src))
src = src.replace(/^https?:/, '');
script.src = src;
document.getElementsByTagName("head")[0].appendChild(script);
})();
</script>


</body>
</html>
